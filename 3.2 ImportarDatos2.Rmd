---
####################
##Importar datos 2##
####################
---

```{r, echo=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

# Importar tabla desde pdf online

```{r}
library(tidyverse)
library(tabulizer)
```

```{r}
germanwatch <- "https://germanwatch.org/sites/germanwatch.org/files/Global%20Climate%20Risk%20Index%202019_2.pdf" 
out <- extract_tables(germanwatch) #también se podría utilizar con un pdf en el computador
```

`out` es una lista que contiene todas los elementos extraidos desde el archivo PDF. Al analizar esta lista es posible identificar que los elementos de interé están en los objetos 7, 8, 9 y 10. Sabiendo esto podemos extraer estos objetos y manipularlos para lograr obtener un *data frame*.

```{r}
out <- out[7:10] #seleccionando los objetos de interés
```

## Transformación de listas a data frame utilizando loop

A continuación se describe una versión simple de un *for loop*.

```{r}
for (i in 1:5) {
  print(i)
}
```

Teniedo esto en cuenta, el siguiente *loop* limpia para una de las tablas que contienen la información de interés para nosotros y almacena cuatro `data frames` en cuatro variables.

```{r}
out1 <- as.data.frame(out[[1]][-c(1:3),c(1:3)])
for (i in 2:4){
  nom <- paste("out", i, sep = "")
  assign(nom, as.data.frame(out[[i]][-c(1:2),c(2:4)]))
}
```

Cada uno de estos *data frame* creados representa una parte de toda la tabla de interés.

## Unir los data frame en uno solo

```{r}
CRI <- rbind(out1, out2, out3, out4) #o bind_rows del paquete deplyr (tambi?n de tidyverse)
colnames(CRI) <- c("CRI Rank", "Country", "CRI Score") # Asignando nombres a cada columna
CRI
```

Este `data frame` ahora puede ser exportado y compartido.

```{r}
write_csv(CRI, "datos_exportados/CRI.csv")
```


# Importar datos desde IMDB de la película Machuca (*web scrapping*).

```{r}
library(rvest)
```

Primero definimos desde donde se obtendrá la información

```{r}
machuca <- read_html("https://www.imdb.com/title/tt0378284/")
```

Extraemos la nota de la pelicula machuca dese IMDB apoyándonos con la extensión de google chrome "selector gadget".

```{r}
machuca2 <- html_node(machuca, "strong span")
machuca2 <- html_text(machuca2)
(machuca2 <- as.numeric(machuca2))
```

O también...

```{r}
(nota <- as.numeric(html_text(html_node(machuca, "strong span"))))
```

Podemos también extrar la lista del elenco de la película

```{r}
elenco <- html_nodes(machuca, ".primary_photo+ td a")
elenco <- html_text(elenco)
elenco <- gsub("\n", "",elenco)
(elenco <- trimws(elenco, "left"))
```

Lo mismo pero escrito de forma distinta

```{r}
trimws(gsub("\n", "", html_text(html_nodes(machuca, ".primary_photo+ td a"))), "left")
```

# Importar tabla de compras desde sitio web de la subsecretaría de pesca

```{r}
library(htmltab)
```

Extrayendo información desde la web para el año 2018

```{r}
url <- "http://www-old.subpesca.cl/transparencia/Otrascompras/2018/otras_compras.html"
compras_2018 <- htmltab(url)
```

Con esa estructura podriamos generalizar nuestra busqueda y extraer la lista de compra de los ultimos 8 años

```{r}
url1 <- "http://www-old.subpesca.cl/transparencia/Otrascompras/"
url2 <- "/otras_compras.html"

for (i in 2010:2018){ #loop que primero considera i=2010, en la segunda vuelta i=2011, etc, hasta i=2018
  year <- as.character(i) #transformar de numérico a caracter
  url <- paste(url1, year, url2, sep = "") #formar la URL completa según el año
  
  #Esto queremos "compras_i" <- htmltab(url) pero se hace as
  assign(paste0("compras_", i), htmltab(url, rm_nodata_cols = F)) #generar variable particular por año e incorporar la tabla importada
}
```


